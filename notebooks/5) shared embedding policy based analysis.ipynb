{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5904cd4",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "In this notebook we will analyse the models that we created.\n",
    "\n",
    "The analysis consists of:\n",
    "\n",
    "1) comparing the perplexity and the accuracy between the rationalized and non-rationalized model \n",
    "\n",
    "2) Checking the change in perplexity when removing even more from the rational\n",
    "\n",
    "3) Checking the distribution of rationals\n",
    "\n",
    "4) Qualitative analysis of the some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263adeb9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbdbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we fix the relative imports\n",
    "import os\n",
    "import sys\n",
    "# M\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "#Make sure we are in the top folder. \n",
    "os.chdir(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerso\\projects\\rational-dialog-model\\utils\\analysis.py:24: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./daily_dialog/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset daily_dialog (C:\\Users\\gerso\\.cache\\huggingface\\datasets\\daily_dialog\\default\\1.0.0\\c03444008e9508b8b76f1f6793742d37d5e5f83364f8d573c2747bff435ea55c)\n"
     ]
    }
   ],
   "source": [
    "### We load the models based on the configs for analysis. \n",
    "from utils.analysis import parse_config_for_analysis\n",
    "config_path = 'configs/simple_RE_config_shared.yml'\n",
    "\n",
    "loaded_info = parse_config_for_analysis(config_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_RE = loaded_info[\"lightning_language_model_RE\"].to(\"cuda\")\n",
    "lm = loaded_info[\"lightning_language_model_no_RE\"].to(\"cuda\")\n",
    "tokenizer = loaded_info[\"tokenizer\"]\n",
    "dataloader_test = loaded_info[\"dataloader_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003d667",
   "metadata": {},
   "source": [
    "## Perplexity and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bfdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First thing we compare the perplexity and accuracy on the testset.\n",
    "from utils.analysis import get_results, get_results_RE\n",
    "\n",
    "lm_RE.hard = True\n",
    "lm_RE_result = get_results_RE(lm_RE, dataloader_test, 5,)\n",
    "lm_result = get_results(lm, dataloader_test)\n",
    "print(lm_RE_result)\n",
    "print(lm_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f45998",
   "metadata": {},
   "source": [
    "## Change in perplexity TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Next we test what happens if we check te change in perplexity of the RE. \n",
    "# from utils.analysis import calc_change_in_perplexity_experiment\n",
    "# change_in_perplexity = calc_change_in_perplexity_experiment(lm_RE, dataloader_test, n_experiments=10, n_extra_mask=1)\n",
    "# change_in_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87500b1b",
   "metadata": {},
   "source": [
    "## Distribution of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d69192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import rational_analysis\n",
    "\n",
    "#Make sure we use the hard (binarized) values\n",
    "\n",
    "\n",
    "rational_distributions = rational_analysis(lm_RE, dataloader_test)\n",
    "print(rational_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "relative_counts = rational_distributions[\"rel_pos_count\"]\n",
    "total = sum(relative_counts.values())\n",
    "X = [int(k) for k in relative_counts.keys()] \n",
    "Y = [r/total for r in relative_counts.values()]\n",
    "\n",
    "pairs = sorted([(x,y) for x,y in zip(X, Y)], key=lambda p: p[0])\n",
    "plt.xlabel\n",
    "X_sorted = [p[0] for p in pairs]\n",
    "Y_sorted = [p[1] for p in pairs]\n",
    "plt.xlabel(\"Relative Distance\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.plot(X_sorted, Y_sorted, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Relative Distance\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.bar(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f07bbd",
   "metadata": {},
   "source": [
    "## Analysing some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"How are you doing?\", \"What did you do today?\", \"How's work?\", \"Would you like some coffee?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0492d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First with greedy rationals\n",
    "completed_dialogue = lm_RE.complete_dialogues(examples, total_length=40, greedy_rationals=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b711811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import pretty_print_completed_dialogues\n",
    "pretty_print_completed_dialogues(completed_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_dialogues_chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1700c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c2543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442bac6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
