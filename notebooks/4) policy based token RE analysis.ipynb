{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5904cd4",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "In this notebook we will analyse the models that we created.\n",
    "\n",
    "The analysis consists of:\n",
    "\n",
    "1) comparing the perplexity and the accuracy between the rationalized and non-rationalized model \n",
    "\n",
    "2) Checking the change in perplexity when removing even more from the rational\n",
    "\n",
    "3) Checking the distribution of rationals\n",
    "\n",
    "4) Qualitative analysis of the some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263adeb9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcbdbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we fix the relative imports\n",
    "import os\n",
    "import sys\n",
    "# M\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "#Make sure we are in the top folder. \n",
    "os.chdir(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b583e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerso\\projects\\rational-dialog-model\\utils\\analysis.py:24: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./daily_dialog/tokenizer.json\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset daily_dialog (C:\\Users\\gerso\\.cache\\huggingface\\datasets\\daily_dialog\\default\\1.0.0\\c03444008e9508b8b76f1f6793742d37d5e5f83364f8d573c2747bff435ea55c)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrained_model:  ./models/small_lm.pt\n",
      "load pretrained_model:  ./models/small_lm_token_rationalized.pt\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "### We load the models based on the configs for analysis. \n",
    "from utils.analysis import parse_config_for_analysis\n",
    "config_path = 'configs/simple_RE_config.yml'\n",
    "\n",
    "loaded_info = parse_config_for_analysis(config_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003d667",
   "metadata": {},
   "source": [
    "## Perplexity and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f347d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_RE = loaded_info[\"lightning_language_model_RE\"].to(\"cuda\")\n",
    "lm = loaded_info[\"lightning_language_model_no_RE\"].to(\"cuda\")\n",
    "tokenizer = loaded_info[\"tokenizer\"]\n",
    "dataloader_test = loaded_info[\"dataloader_test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bfdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/735 [00:00<?, ?it/s]C:\\Users\\gerso\\anaconda3\\envs\\CDM\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 735/735 [00:03<00:00, 186.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 735/735 [00:02<00:00, 312.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_acc': {'mean': 0.36618857776493857, 'std': 0.0}, 'mean_perplexity': {'mean': 30.240165977270287, 'std': 0.0}, 'mean_mask_percentage': {'mean': 0.23160764725132002, 'std': 0.0}}\n",
      "{'mean_acc': 0.3865536399200871, 'mean_perplexity': 25.97224727303416, 'mean_mask_percentage': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### First thing we compare the perplexity and accuracy on the testset.\n",
    "from utils.analysis import get_results, get_results_RE\n",
    "\n",
    "\n",
    "lm_RE_result = get_results_RE(lm_RE, dataloader_test, 1)\n",
    "lm_result = get_results(lm, dataloader_test)\n",
    "print(lm_RE_result)\n",
    "print(lm_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f45998",
   "metadata": {},
   "source": [
    "## Change in perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c532a957",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 5.88 MiB free; 6.48 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b7d57dc53d7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Next we test what happens if we check te change in perplexity of the RE.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcalc_change_in_perplexity_experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mchange_in_perplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_change_in_perplexity_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm_RE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_experiments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_extra_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mchange_in_perplexity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\rational-dialog-model\\utils\\analysis.py\u001b[0m in \u001b[0;36mcalc_change_in_perplexity_experiment\u001b[1;34m(model, dataloader, n_experiments, n_extra_mask)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_experiments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mtotal_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_change_in_perplexity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_extra_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_extra_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mall_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\rational-dialog-model\\utils\\analysis.py\u001b[0m in \u001b[0;36mcalc_change_in_perplexity\u001b[1;34m(model, dataloader, n_extra_mask)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mmask_token_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_token_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mask_token\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mextra_masked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask_extra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_extra_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mlogits_altered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_masked_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_masked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_targets\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;31m# Get the perplexity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\rational-dialog-model\\modules\\pytorch_lightning\\LightningReinforceRationalizedLanguageModel.py\u001b[0m in \u001b[0;36mforward_masked_input\u001b[1;34m(self, masked_input, targets)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mlm_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmasked_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlm_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CDM\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\projects\\rational-dialog-model\\modules\\LanguageModels\\LstmLanguageModel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mclassification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CDM\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CDM\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CDM\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 5.88 MiB free; 6.48 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "### Next we test what happens if we check te change in perplexity of the RE. \n",
    "# from utils.analysis import calc_change_in_perplexity_experiment\n",
    "# change_in_perplexity = calc_change_in_perplexity_experiment(lm_RE, dataloader_test, n_experiments=10, n_extra_mask=2)\n",
    "# change_in_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87500b1b",
   "metadata": {},
   "source": [
    "## Distribution of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d69192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import rational_analysis\n",
    "\n",
    "rational_distributions = rational_analysis(lm_RE, dataloader_test)\n",
    "print(rational_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "relative_counts = rational_distributions[\"rel_pos_count\"]\n",
    "total = sum(relative_counts.values())\n",
    "X = [int(k) for k in relative_counts.keys()] \n",
    "Y = [r/total for r in relative_counts.values()]\n",
    "\n",
    "pairs = sorted([(x,y) for x,y in zip(X, Y)], key=lambda p: p[0])\n",
    "plt.xlabel\n",
    "X_sorted = [p[0] for p in pairs]\n",
    "Y_sorted = [p[1] for p in pairs]\n",
    "plt.xlabel(\"Relative Distance\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.plot(X_sorted, Y_sorted, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Relative Distance\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.bar(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_pos_count = rational_distributions[\"abs_pos_count\"]\n",
    "plt.plt(abs_pos_count.keys(),abs_pos_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f07bbd",
   "metadata": {},
   "source": [
    "## Analysing some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"How are you doing?\", \"What did you do today?\", \"How's work?\", \"Would you like some coffee?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0492d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First with greedy rationals\n",
    "completed_dialogues_chance = lm_RE.complete_dialogues(examples, total_length=40, greedy_rationals=False)\n",
    "completed_dialogues_greedy = lm_RE.complete_dialogues(examples, total_length=40, greedy_rationals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b711811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis import pretty_print_completed_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_completed_dialogues(completed_dialogues_greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1700c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_completed_dialogues(completed_dialogues_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c2543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
